{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with the data you provided\n",
    "data = {'place': }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the 'place' column into two columns using '-' as the separator\n",
    "df[['place_name', 'city']] = df['place'].str.split('-', n=1, expand=True)\n",
    "\n",
    "# Strip leading and trailing whitespaces from the 'city' column\n",
    "df['city'] = df['city'].str.strip()\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('/Users/rewanabdelqader/Collage/Semster 8/Graduation Project/DS/places csv.csv')\n",
    "\n",
    "# Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Replace NaN with an empty string\n",
    "df['place_name'] = df['place_name'].fillna('')\n",
    "\n",
    "# Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df['place_name'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Construct a reverse map of indices and place names\n",
    "indices = pd.Series(df.index, index=df['place_name']).drop_duplicates()\n",
    "\n",
    "# Define a function that takes in place name as input and outputs the top 10 most similar places sorted by rating\n",
    "def get_similar_places(place_name, cosine_sim=cosine_sim, df=df):\n",
    "    # Get the index of the place that matches the title\n",
    "    idx = indices[place_name]\n",
    "\n",
    "    # Get the pairwise similarity scores of all places with that place\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the places based on the rating\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: df['rating'].iloc[x[0]], reverse=True)\n",
    "\n",
    "    # Get the indices of the top 10 most similar places\n",
    "    place_indices = [x[0] for x in sim_scores[1:11]]\n",
    "\n",
    "    # Return the top 10 most similar places sorted by rating\n",
    "    return df.iloc[place_indices].sort_values(by='rating', ascending=False)\n",
    "\n",
    "# Test the function with some sample inputs\n",
    "similar_places = get_similar_places('Rooftop Lounge & Bar, Alexandria')\n",
    "print(similar_places)\n",
    "\n",
    "similar_places = get_similar_places('Wunder Garten, Alexandria')\n",
    "print(similar_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "df1=pd.read_csv('/Users/rewanabdelqader/Collage/Semster 8/Graduation Project/DS/places csv.csv')\n",
    "df1.head(5)\n",
    "\n",
    "place_id\tplace_name\trating\tpopularity\trating_count\taverage_rating\tbudget\tkeywords\n",
    "0\t1\tMontaza Palace Gardens\t2\t174.313947\t400\t4.0\t300\t['cafe', 'dinner', 'lunch', 'coffee', 'brunch'...\n",
    "1\t2\tExit Games Egypt - Cairo\t2\t170.926290\t200\t5.0\t100\t['cafe', 'dinner', 'pastries', 'breakfast', 't...\n",
    "2\t3\tRoasting House - New Cairo, Cairo\t1\t142.719149\t500\t5.0\t300\t['tea', 'cafe', 'lunch', 'desserts']\n",
    "3\t4\tKharga Oasis\t3\t184.004065\t300\t3.5\t100\t['coffee']\n",
    "4\t5\tThe Secret Chambers Egypt - Cairo\t2\t156.373940\t500\t4.0\t300\t['dinner', 'tea', 'desserts', 'lunch', 'coffee..\n",
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "df1['place_name'] = df1['place_name'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df1['place_name'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n",
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df1.index, index=df1['place_name']).drop_duplicates()\n",
    "# Function that takes in place title as input and outputs most similar movies\n",
    "def get_recommendations(place_name, cosine_sim=cosine_sim):\n",
    "    # Get the index of the place that matches the title\n",
    "    idx = indices[place_name]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all places with that place\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar place\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the place indices\n",
    "    places_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df1['place_name'].iloc[places_indices]\n",
    "    get_recommendations('Rooftop Lounge & Bar, Alexandria')\n",
    "    181       Pegasus Lounge Bar, Alexandria\n",
    "128    Sky Roof Bar & Lounge, Alexandria\n",
    "303                      9 Lounge, Cairo\n",
    "155                       The Bar, Cairo\n",
    "399            The Lodge Bar, Alexandria\n",
    "191       Coffee Lounge - Zamalek, Cairo\n",
    "40                     Buddha-Bar, Cairo\n",
    "126           Mojo Lounge & Grill, Cairo\n",
    "70                   I Bistro Bar, Cairo\n",
    "25                       Roof Bar, Cairo\n",
    "Name: place_name, dtype: object\n",
    "get_recommendations('Wunder Garten, Alexandria')\n",
    "95       Escape It Egypt - Alexandria\n",
    "275         Escape Egypt - Alexandria\n",
    "278       The Room Egypt - Alexandria\n",
    "471                    Alexandria Zoo\n",
    "462        The Key Egypt - Alexandria\n",
    "309          Rooms Egypt - Alexandria\n",
    "280            Alexandria City Center\n",
    "351              Cap d'Or, Alexandria\n",
    "36     Escape Room Egypt - Alexandria\n",
    "185       Breakout Egypt - Alexandria\n",
    "Name: place_name, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load user data\n",
    "user_data = pd.read_csv('/Users/rewanabdelqader/Collage/Semster8/Graduation_Project/DS/Fake Data/User Data.csv')\n",
    "\n",
    "# Create user profile vector\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "user_profile = tfidf_vectorizer.fit_transform(user_data.values.astype('U'))\n",
    "\n",
    "# Load hangout data\n",
    "hangout_data = pd.read_csv('hangout_data.csv')\n",
    "\n",
    "\n",
    "# Create hangout profile vector\n",
    "hangout_profile = tfidf_vectorizer.fit_transform(hangout_data['description'])\n",
    "\n",
    "# Calculate similarity between user profile and hangout profile\n",
    "cosine_similarities = cosine_similarity(user_profile, hangout_profile)\n",
    "\n",
    "# Get hangout recommendations for each user\n",
    "hangout_recommendations = {}\n",
    "for i, row in user_data.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    similarity_scores = list(enumerate(cosine_similarities[i]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:6] # Top 5 similar hangouts\n",
    "    hangout_indices = [i[0] for i in similarity_scores]\n",
    "    hangout_recommendations[user_id] = list(hangout_data.iloc[hangout_indices]['hangout_name'])\n",
    "\n",
    "# Print hangout recommendations for each user\n",
    "for user_id, recommendations in hangout_recommendations.items():\n",
    "    print(f\"Recommendations for user {user_id}:\")\n",
    "    print(', '.join(recommendations))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load user data\n",
    "user_interests = pd.read_csv('user_interests.csv')\n",
    "user_behavior = pd.read_csv('user_behavior.csv')\n",
    "user_photos = pd.read_csv('user_photos.csv')\n",
    "\n",
    "# Combine user data into a single dataframe\n",
    "user_data = pd.concat([user_interests, user_behavior, user_photos], axis=1)\n",
    "\n",
    "# Clean user data\n",
    "user_data = user_data.fillna('')\n",
    "\n",
    "# Create user profile vector\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "user_profile = tfidf_vectorizer.fit_transform(user_data.values.astype('U'))\n",
    "\n",
    "# Load destination data\n",
    "destination_data = pd.read_csv('destination_data.csv')\n",
    "\n",
    "# Clean destination data\n",
    "destination_data = destination_data.fillna('')\n",
    "\n",
    "# Create destination profile vector\n",
    "destination_profile = tfidf_vectorizer.transform(destination_data.values.astype('U'))\n",
    "\n",
    "# Calculate cosine similarity between user profile and destination profiles\n",
    "similarity_scores = cosine_similarity(user_profile, destination_profile)\n",
    "\n",
    "# Create a list of recommended destinations for each user\n",
    "recommendations = []\n",
    "for i in range(len(user_data)):\n",
    "    top_destinations = np.argsort(similarity_scores[i])[::-1][:10]\n",
    "    recommendations.append(list(destination_data.iloc[top_destinations]['destination_name']))\n",
    "\n",
    "# Save recommendations to a file\n",
    "with open('user_recommendations.csv', 'w') as f:\n",
    "    f.write('user_id,recommendations\\n')\n",
    "    for i in range(len(user_data)):\n",
    "        f.write(f'{i+1},\"{\", \".join(recommendations[i])}\"\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
