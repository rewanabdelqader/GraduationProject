{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresnet50\u001b[39;00m \u001b[39mimport\u001b[39;00m ResNet50\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, GlobalAveragePooling2D\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train/', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory('val/', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Define the model architecture\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(365, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_generator, steps_per_epoch=2000, epochs=10, validation_data=test_generator, validation_steps=800)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('places_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data directories\n",
    "train_dir = 'path/to/train/folder'\n",
    "val_dir = 'path/to/validation/folder'\n",
    "test_dir = 'path/to/test/folder'\n",
    "\n",
    "# Set image dimensions and batch size\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "batch_size = 32\n",
    "\n",
    "# Use ImageDataGenerator to preprocess the data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load data\n",
    "data = np.load('/path/to/dataset.npy')\n",
    "labels = np.load('/path/to/labels.npy')\n",
    "\n",
    "# Normalize pixel values\n",
    "data = data / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, horizontal_flip=True, fill_mode='nearest')\n",
    "datagen.fit(X_train)\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(data, labels, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#set up the input data paths\n",
    "train_dir = \"/path/to/train/directory\"\n",
    "validation_dir = \"/path/to/validation/directory\"\n",
    "test_dir = \"/path/to/test/directory\"\n",
    "#set up the data generators with data augmentation for the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "#set up the data generators without data augmentation for the validation and test data\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#set up the batch size and image size\n",
    "batch_size = 32\n",
    "img_size = (256, 256)\n",
    "#set up the train, validation, and test data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "#set up the CNN model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(256,256,3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "#compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n",
    "#evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "image_list = []\n",
    "# Set the path to the dataset folder\n",
    "data_path = \"/Users/rewanabdelqader/Collage/Semster 8/Graduation_Project/DS/Test\"\n",
    "for foldername, subfolders, filenames in os.walk(data_path):\n",
    "    # Loop through all the files in the current directory\n",
    "    for filename in filenames:\n",
    "        # Check if the file is a JPEG image\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # Load the image and append it to the list\n",
    "            image_path = os.path.join(foldername, filename)\n",
    "            image = Image.open(image_path)\n",
    "            image_list.append(image)\n",
    "\n",
    "# Set the ratio of training, validation, and testing data\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Create the directories for training, validation, and testing data\n",
    "train_dir = os.path.join(data_path, \"train\")\n",
    "val_dir = os.path.join(data_path, \"val\")\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "for dir in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "# Loop through the folders in the dataset\n",
    "for folder in os.listdir(data_path):\n",
    "    if folder == \"train\" or folder == \"val\" or folder == \"test\":\n",
    "        continue\n",
    "\n",
    "    # Create the subdirectories for each class in the training, validation, and testing data\n",
    "    train_subdir = os.path.join(train_dir, folder)\n",
    "    val_subdir = os.path.join(val_dir, folder)\n",
    "    test_subdir = os.path.join(test_dir, folder)\n",
    "    for subdir in [train_subdir, val_subdir, test_subdir]:\n",
    "        if not os.path.exists(subdir):\n",
    "            os.makedirs(subdir)\n",
    "\n",
    "    # Get the list of image files in the current class folder\n",
    "    image_files = os.listdir(os.path.join(data_path, folder))\n",
    "\n",
    "    # Shuffle the image files\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Split the image files into training, validation, and testing sets\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * train_ratio)\n",
    "    num_val = int(num_images * val_ratio)\n",
    "    num_test = num_images - num_train - num_val\n",
    "\n",
    "    train_files = image_files[:num_train]\n",
    "    val_files = image_files[num_train:num_train+num_val]\n",
    "    test_files = image_files[num_train+num_val:]\n",
    "\n",
    "    # Copy the image files to the corresponding directories\n",
    "    for file in train_files:\n",
    "        src_path = os.path.join(data_path, folder, file)\n",
    "        dest_path = os.path.join(train_subdir, file)\n",
    "        shutil.copyfile(src_path, dest_path)\n",
    "\n",
    "    for file in val_files:\n",
    "        src_path = os.path.join(data_path, folder, file)\n",
    "        dest_path = os.path.join(val_subdir, file)\n",
    "        shutil.copyfile(src_path, dest_path)\n",
    "\n",
    "    for file in test_files:\n",
    "        src_path = os.path.join(data_path, folder, file)\n",
    "        dest_path = os.path.join(test_subdir, file)\n",
    "        shutil.copyfile(src_path, dest_path)\n",
    "# Write output to a file\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    file.write(\"Data split and copied successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from skimage import io\n",
    "\n",
    "# Define data directory\n",
    "data_dir = '/Users/rewanabdelqader/Collage/Semster8/Graduation_Project/DS/Sample'\n",
    "\n",
    "# Load data\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for label, folder_name in enumerate(os.listdir(data_dir)):\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = io.imread(image_path)\n",
    "        if 'train' in image_name:\n",
    "            X_train.append(image.flatten())\n",
    "            y_train.append(label)\n",
    "        elif 'val' in image_name:\n",
    "            X_val.append(image.flatten())\n",
    "            y_val.append(label)\n",
    "        else:\n",
    "            X_test.append(image.flatten())\n",
    "            y_test.append(label)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on train and validation sets\n",
    "train_preds = model.predict(X_train)\n",
    "val_preds = model.predict(X_val)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Validation accuracy:', val_acc)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_preds = model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define data directory\n",
    "data_dir = './data'\n",
    "\n",
    "# Load data\n",
    "X = []\n",
    "y = []\n",
    "for label, folder_name in enumerate(os.listdir(data_dir)):\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = io.imread(image_path)\n",
    "        X.append(image.flatten())\n",
    "        y.append(label)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on train and test sets\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from skimage import io\n",
    "# Define data directories\n",
    "train_dir = \"/Users/rewanabdelqader/Collage/Semster8/Graduation_Project/DS/Sample/Train\"\n",
    "val_dir = \"/Users/rewanabdelqader/Collage/Semster8/Graduation_Project/DS/Sample/Val\"\n",
    "test_dir = \"/Users/rewanabdelqader/Collage/Semster8/Graduation_Project/DS/Sample/Test\"\n",
    "# Load train data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for label, folder_name in enumerate(os.listdir(train_dir)):\n",
    "    folder_path = os.path.join(train_dir, folder_name)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = io.imread(image_path)\n",
    "        X_train.append(image.flatten())\n",
    "        y_train.append(label)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Load train data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for label, folder_name in enumerate(os.listdir(train_dir)):\n",
    "    folder_path = os.path.join(train_dir, folder_name)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = io.imread(image_path)\n",
    "        X_train.append(image.flatten())\n",
    "        y_train.append(label)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Load test data\n",
    "X_test = []\n",
    "y_test = []\n",
    "for label, folder_name in enumerate(os.listdir(test_dir)):\n",
    "    folder_path = os.path.join(test_dir, folder_name)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = io.imread(image_path)\n",
    "        X_test.append(image.flatten())\n",
    "        y_test.append(label)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Load validation data\n",
    "X_val = []\n",
    "y_val = []\n",
    "for label, folder_name in enumerate(os.listdir(val_dir)):\n",
    "    folder_path = os.path.join(val_dir, folder_name)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = io.imread(image_path)\n",
    "        X_val.append(image.flatten())\n",
    "        y_val.append(label)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on train, validation, and test sets\n",
    "train_preds = model.predict(X_train)\n",
    "val_preds = model.predict(X_val)\n",
    "test_preds = model.predict(X_test)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Validation accuracy:', val_acc)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
